MindBrige_text_only_mixco_loss_diffusers_vit_norm starting with epoch 0 / 500
>>> Epoch0 | Iter0 | voxel: torch.Size([1000, 8192])
  0%|                                                                                                                                                 | 0/500 [00:00<?, ?it/s]
>>> Epoch0 | Iter1 | voxel: torch.Size([1000, 8192])
>>> Epoch0 | Iter2 | voxel: torch.Size([1000, 8192])
>>> Epoch0 | Iter3 | voxel: torch.Size([1000, 8192])
>>> Epoch0 | Iter4 | voxel: torch.Size([1000, 8192])
>>> Epoch0 | Iter5 | voxel: torch.Size([1000, 8192])
>>> Epoch0 | Iter6 | voxel: torch.Size([1000, 8192])
>>> Epoch0 | Iter7 | voxel: torch.Size([1000, 8192])
>>> Epoch0 | Iter8 | voxel: torch.Size([1000, 8192])
>>> Epoch0 | Iter9 | voxel: torch.Size([1000, 8192])
>>> Epoch0 | Iter10 | voxel: torch.Size([1000, 8192])
>>> Epoch0 | Iter11 | voxel: torch.Size([1000, 8192])
>>> Epoch0 | Iter12 | voxel: torch.Size([1000, 8192])
>>> Epoch0 | Iter13 | voxel: torch.Size([1000, 8192])
>>> Epoch0 | Iter14 | voxel: torch.Size([1000, 8192])
>>> Epoch0 | Iter15 | voxel: torch.Size([1000, 8192])
>>> Epoch0 | Iter16 | voxel: torch.Size([1000, 8192])
>>> Epoch0 | Iter17 | voxel: torch.Size([1000, 8192])
>>> Epoch0 | Iter18 | voxel: torch.Size([1000, 8192])
>>> Epoch0 | Iter19 | voxel: torch.Size([1000, 8192])
>>> Epoch0 | Iter20 | voxel: torch.Size([1000, 8192])
>>> Epoch0 | Iter21 | voxel: torch.Size([1000, 8192])
>>> Epoch0 | Iter22 | voxel: torch.Size([1000, 8192])
>>> Epoch0 | Iter23 | voxel: torch.Size([1000, 8192])
>>> Epoch0 | Iter24 | voxel: torch.Size([1000, 8192])
>>> Epoch0 | Iter25 | voxel: torch.Size([1000, 8192])
>>> Epoch0 | Iter26 | voxel: torch.Size([1000, 8192])
>>> Epoch0 | Iter27 | voxel: torch.Size([1000, 8192])
>>> Epoch0 | Iter28 | voxel: torch.Size([1000, 8192])
>>> Epoch0 | Iter29 | voxel: torch.Size([1000, 8192])
>>> Epoch0 | Iter30 | voxel: torch.Size([1000, 8192])
>>> Epoch0 | Iter31 | voxel: torch.Size([1000, 8192])
>>> Epoch0 | Iter32 | voxel: torch.Size([1000, 8192])
>>> Epoch0 | Iter33 | voxel: torch.Size([1000, 8192])
>>> Epoch0 | Iter34 | voxel: torch.Size([236, 8192])
train/loss: 352350.6861607143
train/lr: 0.00025453683251453466
train/num_steps: 35
train/cosine_sim_text: 0.05546520492061972
train/loss_nce_text: 176158.7238839286
train/loss_mse_text: 1.9699703318732125
train/loss_mae_text: 1.1040390832083566
train/loss_rec: 1.0808884637696403
train/loss_cyc: 1.4123314244406564
Evaluating...
>>> Epoch0 | Eval0 | voxel: torch.Size([200, 8192])
>>> Epoch0 | Eval1 | voxel: torch.Size([200, 8192])
>>> Epoch0 | Eval2 | voxel: torch.Size([200, 8192])
>>> Epoch0 | Eval3 | voxel: torch.Size([200, 8192])

  0%|▏                                                                                                  | 1/500 [00:36<5:04:10, 36.57s/it, epoch=0, lr=0.000255, loss=3.52e+5]
>>> Epoch0 | Eval5 | voxel: torch.Size([200, 8192])
val/loss: 197440.0703125
val/num_steps: 6
val/cosine_sim_text: 0.11878740166624387
val/loss_nce_text: 197409.9375
val/loss_mse_text: 1.835697094599406
val/loss_mae_text: 1.0777321259180705
val/loss_rec: 0.4797249386707942
val/loss_cyc: 0.5191982040802637
>>> Epoch1 | Iter0 | voxel: torch.Size([1000, 8192])
>>> Epoch1 | Iter1 | voxel: torch.Size([1000, 8192])
>>> Epoch1 | Iter2 | voxel: torch.Size([1000, 8192])
>>> Epoch1 | Iter3 | voxel: torch.Size([1000, 8192])
>>> Epoch1 | Iter4 | voxel: torch.Size([1000, 8192])
>>> Epoch1 | Iter5 | voxel: torch.Size([1000, 8192])
>>> Epoch1 | Iter6 | voxel: torch.Size([1000, 8192])
>>> Epoch1 | Iter7 | voxel: torch.Size([1000, 8192])
>>> Epoch1 | Iter8 | voxel: torch.Size([1000, 8192])
>>> Epoch1 | Iter9 | voxel: torch.Size([1000, 8192])
>>> Epoch1 | Iter10 | voxel: torch.Size([1000, 8192])
>>> Epoch1 | Iter11 | voxel: torch.Size([1000, 8192])
>>> Epoch1 | Iter12 | voxel: torch.Size([1000, 8192])
>>> Epoch1 | Iter13 | voxel: torch.Size([1000, 8192])
>>> Epoch1 | Iter14 | voxel: torch.Size([1000, 8192])
>>> Epoch1 | Iter15 | voxel: torch.Size([1000, 8192])
>>> Epoch1 | Iter16 | voxel: torch.Size([1000, 8192])
>>> Epoch1 | Iter17 | voxel: torch.Size([1000, 8192])
>>> Epoch1 | Iter18 | voxel: torch.Size([1000, 8192])
>>> Epoch1 | Iter19 | voxel: torch.Size([1000, 8192])
>>> Epoch1 | Iter20 | voxel: torch.Size([1000, 8192])
>>> Epoch1 | Iter21 | voxel: torch.Size([1000, 8192])
>>> Epoch1 | Iter22 | voxel: torch.Size([1000, 8192])
>>> Epoch1 | Iter23 | voxel: torch.Size([1000, 8192])
>>> Epoch1 | Iter24 | voxel: torch.Size([1000, 8192])
>>> Epoch1 | Iter25 | voxel: torch.Size([1000, 8192])
>>> Epoch1 | Iter26 | voxel: torch.Size([1000, 8192])
>>> Epoch1 | Iter27 | voxel: torch.Size([1000, 8192])
>>> Epoch1 | Iter28 | voxel: torch.Size([1000, 8192])
>>> Epoch1 | Iter29 | voxel: torch.Size([1000, 8192])
>>> Epoch1 | Iter30 | voxel: torch.Size([1000, 8192])
>>> Epoch1 | Iter31 | voxel: torch.Size([1000, 8192])
>>> Epoch1 | Iter32 | voxel: torch.Size([1000, 8192])
>>> Epoch1 | Iter33 | voxel: torch.Size([1000, 8192])
>>> Epoch1 | Iter34 | voxel: torch.Size([236, 8192])
train/loss: 519396.7294642857
train/lr: 0.0005
train/num_steps: 70
train/cosine_sim_text: 0.11375794644866671
train/loss_nce_text: 259682.64642857143
train/loss_mse_text: 1.8408728769847325
train/loss_mae_text: 1.0861817734582084
train/loss_rec: 0.8133706365312848
train/loss_cyc: 1.3482168844767979
Evaluating...
>>> Epoch1 | Eval0 | voxel: torch.Size([200, 8192])
>>> Epoch1 | Eval1 | voxel: torch.Size([200, 8192])
>>> Epoch1 | Eval2 | voxel: torch.Size([200, 8192])
>>> Epoch1 | Eval3 | voxel: torch.Size([200, 8192])
>>> Epoch1 | Eval4 | voxel: torch.Size([200, 8192])
>>> Epoch1 | Eval5 | voxel: torch.Size([200, 8192])
val/loss: 121334.24088541667
val/num_steps: 12
val/cosine_sim_text: 0.10521328697601955
val/loss_nce_text: 121303.95572916667
val/loss_mse_text: 1.8522090117136638
val/loss_mae_text: 1.0933051307996113
val/loss_rec: 0.34614430367946625
val/loss_cyc: 0.4797445883353551
Not best - current_similarity: 0.105 @ epoch 1, best_similarity: 0.119 @ epoch 0

  0%|▍                                                                                                    | 2/500 [01:12<5:01:28, 36.32s/it, epoch=1, lr=0.0005, loss=5.19e+5]
>>> Epoch2 | Iter1 | voxel: torch.Size([1000, 8192])
>>> Epoch2 | Iter2 | voxel: torch.Size([1000, 8192])
>>> Epoch2 | Iter3 | voxel: torch.Size([1000, 8192])
>>> Epoch2 | Iter4 | voxel: torch.Size([1000, 8192])
>>> Epoch2 | Iter5 | voxel: torch.Size([1000, 8192])
>>> Epoch2 | Iter6 | voxel: torch.Size([1000, 8192])
>>> Epoch2 | Iter7 | voxel: torch.Size([1000, 8192])
>>> Epoch2 | Iter8 | voxel: torch.Size([1000, 8192])
>>> Epoch2 | Iter9 | voxel: torch.Size([1000, 8192])
>>> Epoch2 | Iter10 | voxel: torch.Size([1000, 8192])
>>> Epoch2 | Iter11 | voxel: torch.Size([1000, 8192])
>>> Epoch2 | Iter12 | voxel: torch.Size([1000, 8192])
>>> Epoch2 | Iter13 | voxel: torch.Size([1000, 8192])
>>> Epoch2 | Iter14 | voxel: torch.Size([1000, 8192])
>>> Epoch2 | Iter15 | voxel: torch.Size([1000, 8192])
>>> Epoch2 | Iter16 | voxel: torch.Size([1000, 8192])
>>> Epoch2 | Iter17 | voxel: torch.Size([1000, 8192])
>>> Epoch2 | Iter18 | voxel: torch.Size([1000, 8192])
>>> Epoch2 | Iter19 | voxel: torch.Size([1000, 8192])
>>> Epoch2 | Iter20 | voxel: torch.Size([1000, 8192])
>>> Epoch2 | Iter21 | voxel: torch.Size([1000, 8192])
>>> Epoch2 | Iter22 | voxel: torch.Size([1000, 8192])
>>> Epoch2 | Iter23 | voxel: torch.Size([1000, 8192])
>>> Epoch2 | Iter24 | voxel: torch.Size([1000, 8192])
>>> Epoch2 | Iter25 | voxel: torch.Size([1000, 8192])
>>> Epoch2 | Iter26 | voxel: torch.Size([1000, 8192])
>>> Epoch2 | Iter27 | voxel: torch.Size([1000, 8192])
>>> Epoch2 | Iter28 | voxel: torch.Size([1000, 8192])
>>> Epoch2 | Iter29 | voxel: torch.Size([1000, 8192])
>>> Epoch2 | Iter30 | voxel: torch.Size([1000, 8192])
>>> Epoch2 | Iter31 | voxel: torch.Size([1000, 8192])
>>> Epoch2 | Iter32 | voxel: torch.Size([1000, 8192])
>>> Epoch2 | Iter33 | voxel: torch.Size([1000, 8192])
>>> Epoch2 | Iter34 | voxel: torch.Size([236, 8192])
train/loss: 287266.2290178572
train/lr: 0.0004999950274875398
train/num_steps: 105
train/cosine_sim_text: 0.09428325380597796
train/loss_nce_text: 143617.35446428572
train/loss_mse_text: 1.8705221346446446
train/loss_mae_text: 1.0997780323028565
train/loss_rec: 0.7068976606641497
train/loss_cyc: 1.112218201160431
Evaluating...
>>> Epoch2 | Eval0 | voxel: torch.Size([200, 8192])
>>> Epoch2 | Eval1 | voxel: torch.Size([200, 8192])
>>> Epoch2 | Eval2 | voxel: torch.Size([200, 8192])
>>> Epoch2 | Eval3 | voxel: torch.Size([200, 8192])
>>> Epoch2 | Eval4 | voxel: torch.Size([200, 8192])
>>> Epoch2 | Eval5 | voxel: torch.Size([200, 8192])
val/loss: 75493.30859375
val/num_steps: 18
val/cosine_sim_text: 0.09091885760426521
val/loss_nce_text: 75462.91145833333
val/loss_mse_text: 1.8735415538152058
val/loss_mae_text: 1.1013807853062947
val/loss_rec: 0.33279871940612793
val/loss_cyc: 0.31592002511024475
Not best - current_similarity: 0.091 @ epoch 2, best_similarity: 0.119 @ epoch 0

  1%|▌                                                                                                    | 3/500 [01:48<5:00:34, 36.29s/it, epoch=2, lr=0.0005, loss=2.87e+5]
>>> Epoch3 | Iter1 | voxel: torch.Size([1000, 8192])
>>> Epoch3 | Iter2 | voxel: torch.Size([1000, 8192])
>>> Epoch3 | Iter3 | voxel: torch.Size([1000, 8192])
>>> Epoch3 | Iter4 | voxel: torch.Size([1000, 8192])
>>> Epoch3 | Iter5 | voxel: torch.Size([1000, 8192])
>>> Epoch3 | Iter6 | voxel: torch.Size([1000, 8192])
>>> Epoch3 | Iter7 | voxel: torch.Size([1000, 8192])
>>> Epoch3 | Iter8 | voxel: torch.Size([1000, 8192])
>>> Epoch3 | Iter9 | voxel: torch.Size([1000, 8192])
>>> Epoch3 | Iter10 | voxel: torch.Size([1000, 8192])
>>> Epoch3 | Iter11 | voxel: torch.Size([1000, 8192])
>>> Epoch3 | Iter12 | voxel: torch.Size([1000, 8192])
>>> Epoch3 | Iter13 | voxel: torch.Size([1000, 8192])
>>> Epoch3 | Iter14 | voxel: torch.Size([1000, 8192])
>>> Epoch3 | Iter15 | voxel: torch.Size([1000, 8192])
>>> Epoch3 | Iter16 | voxel: torch.Size([1000, 8192])
>>> Epoch3 | Iter17 | voxel: torch.Size([1000, 8192])
>>> Epoch3 | Iter18 | voxel: torch.Size([1000, 8192])
>>> Epoch3 | Iter19 | voxel: torch.Size([1000, 8192])
>>> Epoch3 | Iter20 | voxel: torch.Size([1000, 8192])
>>> Epoch3 | Iter21 | voxel: torch.Size([1000, 8192])
>>> Epoch3 | Iter22 | voxel: torch.Size([1000, 8192])
>>> Epoch3 | Iter23 | voxel: torch.Size([1000, 8192])
>>> Epoch3 | Iter24 | voxel: torch.Size([1000, 8192])
>>> Epoch3 | Iter25 | voxel: torch.Size([1000, 8192])
>>> Epoch3 | Iter26 | voxel: torch.Size([1000, 8192])
>>> Epoch3 | Iter27 | voxel: torch.Size([1000, 8192])
>>> Epoch3 | Iter28 | voxel: torch.Size([1000, 8192])
>>> Epoch3 | Iter29 | voxel: torch.Size([1000, 8192])
>>> Epoch3 | Iter30 | voxel: torch.Size([1000, 8192])
>>> Epoch3 | Iter31 | voxel: torch.Size([1000, 8192])
>>> Epoch3 | Iter32 | voxel: torch.Size([1000, 8192])
>>> Epoch3 | Iter33 | voxel: torch.Size([1000, 8192])
>>> Epoch3 | Iter34 | voxel: torch.Size([236, 8192])
train/loss: 212747.81383928572
train/lr: 0.0004999801101480454
train/num_steps: 140
train/cosine_sim_text: 0.08866895777838571
train/loss_nce_text: 106358.2017857143
train/loss_mse_text: 1.875026982171195
train/loss_mae_text: 1.1015110867364066
train/loss_rec: 0.6845603925841195
train/loss_cyc: 0.9630074432918003
Evaluating...
>>> Epoch3 | Eval0 | voxel: torch.Size([200, 8192])
>>> Epoch3 | Eval1 | voxel: torch.Size([200, 8192])
>>> Epoch3 | Eval2 | voxel: torch.Size([200, 8192])
>>> Epoch3 | Eval3 | voxel: torch.Size([200, 8192])
>>> Epoch3 | Eval4 | voxel: torch.Size([200, 8192])
>>> Epoch3 | Eval5 | voxel: torch.Size([200, 8192])
val/loss: 78278.83463541667
val/num_steps: 24
val/cosine_sim_text: 0.08735710258285205
val/loss_nce_text: 78248.44010416667
val/loss_mse_text: 1.8746296763420105
val/loss_mae_text: 1.1017616391181946
val/loss_rec: 0.3266004870335261
val/loss_cyc: 0.30126501619815826
Not best - current_similarity: 0.087 @ epoch 3, best_similarity: 0.119 @ epoch 0

  1%|▊                                                                                                    | 4/500 [02:25<4:59:39, 36.25s/it, epoch=3, lr=0.0005, loss=2.13e+5]
>>> Epoch4 | Iter1 | voxel: torch.Size([1000, 8192])
>>> Epoch4 | Iter2 | voxel: torch.Size([1000, 8192])
>>> Epoch4 | Iter3 | voxel: torch.Size([1000, 8192])
>>> Epoch4 | Iter4 | voxel: torch.Size([1000, 8192])
>>> Epoch4 | Iter5 | voxel: torch.Size([1000, 8192])
>>> Epoch4 | Iter6 | voxel: torch.Size([1000, 8192])
>>> Epoch4 | Iter7 | voxel: torch.Size([1000, 8192])
>>> Epoch4 | Iter8 | voxel: torch.Size([1000, 8192])
>>> Epoch4 | Iter9 | voxel: torch.Size([1000, 8192])
>>> Epoch4 | Iter10 | voxel: torch.Size([1000, 8192])
>>> Epoch4 | Iter11 | voxel: torch.Size([1000, 8192])
>>> Epoch4 | Iter12 | voxel: torch.Size([1000, 8192])
>>> Epoch4 | Iter13 | voxel: torch.Size([1000, 8192])
>>> Epoch4 | Iter14 | voxel: torch.Size([1000, 8192])
>>> Epoch4 | Iter15 | voxel: torch.Size([1000, 8192])
>>> Epoch4 | Iter16 | voxel: torch.Size([1000, 8192])
>>> Epoch4 | Iter17 | voxel: torch.Size([1000, 8192])
>>> Epoch4 | Iter18 | voxel: torch.Size([1000, 8192])
>>> Epoch4 | Iter19 | voxel: torch.Size([1000, 8192])
>>> Epoch4 | Iter20 | voxel: torch.Size([1000, 8192])
>>> Epoch4 | Iter21 | voxel: torch.Size([1000, 8192])
>>> Epoch4 | Iter22 | voxel: torch.Size([1000, 8192])
>>> Epoch4 | Iter23 | voxel: torch.Size([1000, 8192])
>>> Epoch4 | Iter24 | voxel: torch.Size([1000, 8192])
>>> Epoch4 | Iter25 | voxel: torch.Size([1000, 8192])
>>> Epoch4 | Iter26 | voxel: torch.Size([1000, 8192])
>>> Epoch4 | Iter27 | voxel: torch.Size([1000, 8192])
>>> Epoch4 | Iter28 | voxel: torch.Size([1000, 8192])
>>> Epoch4 | Iter29 | voxel: torch.Size([1000, 8192])
>>> Epoch4 | Iter30 | voxel: torch.Size([1000, 8192])
>>> Epoch4 | Iter31 | voxel: torch.Size([1000, 8192])
>>> Epoch4 | Iter32 | voxel: torch.Size([1000, 8192])
>>> Epoch4 | Iter33 | voxel: torch.Size([1000, 8192])
>>> Epoch4 | Iter34 | voxel: torch.Size([236, 8192])
train/loss: 184604.35
train/lr: 0.0004999552485751675
train/num_steps: 175
train/cosine_sim_text: 0.08791151131902422
train/loss_nce_text: 92286.59107142857
train/loss_mse_text: 1.8708536795207433
train/loss_mae_text: 1.1001926285879953
train/loss_rec: 0.6733986599104745
train/loss_cyc: 0.7833434275218418
Evaluating...
>>> Epoch4 | Eval0 | voxel: torch.Size([200, 8192])

  1%|█                                                                                                    | 5/500 [03:01<4:59:04, 36.25s/it, epoch=4, lr=0.0005, loss=1.85e+5]
>>> Epoch4 | Eval2 | voxel: torch.Size([200, 8192])
>>> Epoch4 | Eval3 | voxel: torch.Size([200, 8192])
>>> Epoch4 | Eval4 | voxel: torch.Size([200, 8192])
>>> Epoch4 | Eval5 | voxel: torch.Size([200, 8192])
val/loss: 60833.845052083336
val/num_steps: 30
val/cosine_sim_text: 0.08380806321899097
val/loss_nce_text: 60803.505208333336
val/loss_mse_text: 1.8763540387153625
val/loss_mae_text: 1.1023550828297932
val/loss_rec: 0.32131655017534894
val/loss_cyc: 0.23322291920582452
Not best - current_similarity: 0.084 @ epoch 4, best_similarity: 0.119 @ epoch 0
>>> Epoch5 | Iter0 | voxel: torch.Size([1000, 8192])
>>> Epoch5 | Iter1 | voxel: torch.Size([1000, 8192])
  1%|█                                                                                                    | 5/500 [03:05<5:05:50, 37.07s/it, epoch=4, lr=0.0005, loss=1.85e+5]
Traceback (most recent call last):
  File "/media/SSD_1_2T/xt/MindBridge/src/main.py", line 239, in <module>
    main()
  File "/media/SSD_1_2T/xt/MindBridge/src/main.py", line 233, in main
    trainer.train(local_rank)
  File "/media/SSD_1_2T/xt/MindBridge/src/trainer_fmri_text.py", line 160, in train
    self.train_epoch(epoch)
  File "/media/SSD_1_2T/xt/MindBridge/src/trainer_fmri_text.py", line 656, in train_epoch
    self.train_step(voxel, captions, subj_id, epoch)
  File "/media/SSD_1_2T/xt/MindBridge/src/trainer_fmri_text.py", line 202, in train_step
    results = self.voxel2clip(self.input(voxel, subj_id))
  File "/home/fmri/miniconda3/envs/xt/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/fmri/miniconda3/envs/xt/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1541, in _call_impl
    return forward_call(*args, **kwargs)
  File "/media/SSD_1_2T/xt/MindBridge/src/models.py", line 636, in forward
    subj_list = x[1].tolist()  # (s,)
KeyboardInterrupt