
  0%|                                                                                                                                                 | 0/400 [00:00<?, ?it/s]
MindBrige_image_GIT_ViT_infonce_token starting with epoch 0 / 400
  0%|                                                                                                                                                 | 0/400 [00:05<?, ?it/s]
Traceback (most recent call last):
  File "/media/SSD_1_2T/xt/MindBridge/src/main.py", line 333, in <module>
    main()
  File "/media/SSD_1_2T/xt/MindBridge/src/main.py", line 327, in main
    trainer.train(local_rank)
  File "/media/SSD_1_2T/xt/MindBridge/src/trainer_fmri_img_GIT.py", line 166, in train
    self.train_epoch(epoch)
  File "/media/SSD_1_2T/xt/MindBridge/src/trainer_fmri_img_GIT.py", line 552, in train_epoch
    self.train_step(voxel, image, subj_id, epoch)
  File "/media/SSD_1_2T/xt/MindBridge/src/trainer_fmri_img_GIT.py", line 246, in train_step
    self.accelerator.backward(loss)
  File "/home/fmri/miniconda3/envs/xt/lib/python3.10/site-packages/accelerate/accelerator.py", line 2151, in backward
    loss.backward(**kwargs)
  File "/home/fmri/miniconda3/envs/xt/lib/python3.10/site-packages/torch/_tensor.py", line 492, in backward
    torch.autograd.backward(
  File "/home/fmri/miniconda3/envs/xt/lib/python3.10/site-packages/torch/autograd/__init__.py", line 251, in backward
    Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 578.00 MiB. GPU 0 has a total capacty of 23.64 GiB of which 527.06 MiB is free. Process 3961868 has 503.28 MiB memory in use. Process 305525 has 386.00 MiB memory in use. Including non-PyTorch memory, this process has 21.86 GiB memory in use. Of the allocated memory 19.85 GiB is allocated by PyTorch, and 1.55 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
>>> Epoch0 | Iter1 | voxel: torch.Size([1000, 8192])